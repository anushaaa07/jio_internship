{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOse7zrDn3UX3XEPU4ApJqG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anushaaa07/jio_internship/blob/main/w2v_finetuning_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOzGoxqJH9Xw",
        "outputId": "01aa8e4f-af46-4abb-e5cc-579e01b48292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "# Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora.\n",
        "# Target audience is the natural language processing (NLP) and information retrieval (IR) community.\n",
        "# Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.\n",
        "!pip install gensim PyPDF2 transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from google.colab import files\n",
        "import PyPDF2\n",
        "\n",
        "# Uploaded the research paper from laptop\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Took string text as input, tokenized the input text removing punctuation and then filtered out tokens that are in the predefined list of stopwords\n",
        "\n",
        "def preprocess(text):\n",
        "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file: # Opened the PDF file in binary read mode\n",
        "        # Used PdfReader instead of the deprecated PdfFileReader\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\" # Initialized an empty string text to store the extracted text\n",
        "        # Used len(reader.pages) to get the number of pages\n",
        "        for page_num in range(len(reader.pages)): # Iterating over each page in the PDF\n",
        "            text += reader.pages[page_num].extract_text() # Extracting text from the current page and appended it to the text string\n",
        "    return text\n",
        "\n",
        "# Processed the uploaded file\n",
        "documents = [] # Initialized an empty list documents to store the preprocessed text of the pdf\n",
        "for filename in uploaded.keys(): # Iterated over each filename in the uploaded files.\n",
        "    text = extract_text_from_pdf(filename) # Extracted text from the PDF file using the previously defined function\n",
        "    documents.append(preprocess(text)) # Preprocesses the extracted text and appended the result to the documents list\n",
        "\n",
        "print(\"Preprocessing completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "EGgJ0LhNJTcB",
        "outputId": "d7cb69f4-4f9a-43f7-bf74-c8f3db14140a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5a82a218-6195-45eb-81d0-0b37dd702d1c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5a82a218-6195-45eb-81d0-0b37dd702d1c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving research.pdf to research.pdf\n",
            "Preprocessing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Loaded the Word2Vec model directly using Gensim\n",
        "model_name = \"word2vec-google-news-300\" #Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases.\n",
        "model = api.load(model_name)\n",
        "\n",
        "print(\"Pre-trained model loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PXieyRmJwx5",
        "outputId": "1796a86a-3399-4b52-9509-7b2f48bef615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Pre-trained model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Converted tokenized documents back to sentences\n",
        "sentences = [\" \".join(doc) for doc in documents]\n",
        "\n",
        "# Trained a new Word2Vec model on the research paper\n",
        "new_model = Word2Vec(sentences=[doc.split() for doc in sentences], vector_size=300, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Trained the new model, providing the sentences as the corpus_iterable\n",
        "new_model.train(corpus_iterable=[doc.split() for doc in sentences], total_examples=new_model.corpus_count, epochs=new_model.epochs) # Pass the sentences as corpus_iterable\n",
        "\n",
        "# Saved the fine-tuned model\n",
        "new_model.save('word2vec_finetuned.model')\n",
        "\n",
        "print(\"Fine-tuning completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEn-Go3BMzSZ",
        "outputId": "d112ce00-20d6-4a71-fe87-aeeea2f47389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot # dot product of two arrays.\n",
        "from numpy.linalg import norm # norm is a way to measure the size of a vector\n",
        "import numpy as np\n",
        "\n",
        "# Example fixed sentence used\n",
        "fixed_sentence = \"The Falcon model outperforms previous models achieving 70% accuracy with human evaluation on Spider dataset and it achieves competitive 75% accuracy with human evaluation on WikiSQL dataset.\"\n",
        "tokens = preprocess(fixed_sentence)\n",
        "\n",
        "# Function to get average vector from Word2Vec model\n",
        "def get_average_vector(model, tokens):\n",
        "    vectors = [model[token] for token in tokens if token in model]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Got vector for the fixed sentence from pre-trained model\n",
        "baseline_vector = get_average_vector(model, tokens)\n",
        "\n",
        "# Loaded fine-tuned Word2Vec model\n",
        "finetuned_model = Word2Vec.load('word2vec_finetuned.model')\n",
        "\n",
        "# Got average vector for the sentence from fine-tuned model\n",
        "finetuned_vector = get_average_vector(finetuned_model.wv, tokens)\n",
        "\n",
        "# Printed the vectors as well as their sizes/dimensions\n",
        "\n",
        "print(\"Baseline Vector:\", baseline_vector)\n",
        "print(\"Dimensions/Size of Baseline Vector:\", baseline_vector.shape[0] if baseline_vector is not None else \"None\")\n",
        "print(\"Fine-tuned Vector:\", finetuned_vector)\n",
        "print(\"Dimensions/Size of Fine-tuned Vector:\", finetuned_vector.shape[0] if finetuned_vector is not None else \"None\")\n",
        "\n",
        "# Calculated cosine similarity\n",
        "if baseline_vector is not None and finetuned_vector is not None:\n",
        "    cosine_similarity = dot(baseline_vector, finetuned_vector) / (norm(baseline_vector) * norm(finetuned_vector))\n",
        "    print(\"Cosine Similarity between baseline and fine-tuned vectors:\", cosine_similarity)\n",
        "else:\n",
        "    print(\"One or both vectors are None, cannot compute cosine similarity.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfN7NsGdBlgn",
        "outputId": "3dfcf8dd-43a7-4a0f-f33b-00de23862fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Vector: [-5.12345247e-02  4.41993251e-02  7.76403071e-03  4.71370928e-02\n",
            "  4.37909290e-02  1.65692493e-02  8.07333589e-02 -9.72684994e-02\n",
            "  1.44114777e-01  1.05676986e-01 -9.51645821e-02 -1.50282919e-01\n",
            "  9.81445312e-02  2.76166126e-02  4.65303287e-03  1.66661873e-01\n",
            " -8.50327462e-02  4.46813256e-02 -5.90106733e-02 -1.56120747e-01\n",
            " -1.47051647e-01 -4.40027565e-02 -1.69390514e-01  1.23352051e-01\n",
            " -2.70367786e-02 -1.05341688e-01 -2.70593971e-01  6.58605248e-02\n",
            "  1.48064112e-02 -6.98314011e-02 -3.25137861e-02 -1.13913141e-01\n",
            " -6.20691627e-02  2.52283886e-02 -9.08992961e-02 -1.28055457e-02\n",
            " -5.47377653e-02 -2.59596873e-02  1.89287975e-01  2.68985517e-02\n",
            "  1.06089875e-01  7.16409087e-02 -5.29856980e-02  2.29391664e-01\n",
            " -3.80572141e-03 -1.38420552e-01 -2.95561627e-02  4.36446251e-04\n",
            "  9.26298276e-02  3.43233012e-02 -3.04170493e-02 -1.89855248e-02\n",
            " -7.76151791e-02 -4.99016270e-02 -4.27658968e-02  6.06043190e-02\n",
            "  3.26430388e-02 -1.42937154e-01  9.02674049e-02  6.89194649e-02\n",
            "  8.85727815e-03  6.88548386e-02 -8.10834095e-02 -1.26292512e-01\n",
            " -1.96452420e-02  4.99483012e-02  1.85439165e-03  4.69306484e-02\n",
            " -9.35992040e-03 -2.11827899e-03  1.85762290e-02 -1.30547017e-01\n",
            "  1.20907053e-01 -1.13823384e-01 -5.68488613e-02 -1.95886940e-02\n",
            "  1.10075109e-01 -3.54003906e-03  1.17546529e-01  9.88159180e-02\n",
            "  4.53073829e-02  3.45723778e-02  3.35226618e-02 -7.00369477e-02\n",
            "  8.36325288e-02  5.79618551e-02 -5.25063910e-02  9.06910598e-02\n",
            "  3.15659456e-02  3.15982588e-02  9.12655070e-02 -1.73009530e-01\n",
            " -8.33381191e-02  6.53219819e-02  1.79192033e-02 -6.12433925e-02\n",
            " -2.02385392e-02 -7.46100917e-02  1.00988053e-01 -2.03282982e-02\n",
            "  8.64203945e-02 -8.69014934e-02 -2.41842829e-02 -1.89087819e-02\n",
            " -7.48219201e-03  1.79694686e-03 -1.73138782e-01  8.07872117e-02\n",
            "  1.29897175e-02 -4.28359099e-02  5.11977263e-03  5.08817770e-02\n",
            " -1.03544347e-01  1.26263782e-01  5.67492321e-02  7.21650943e-02\n",
            " -1.02050781e-01 -1.56601846e-01  1.23088166e-01 -5.67950085e-02\n",
            " -1.18120976e-01 -3.87636088e-02 -8.23974609e-02  4.60851341e-02\n",
            " -6.81439554e-03  9.74210873e-02 -7.28436634e-02  1.50451660e-02\n",
            " -7.89866690e-03  6.18124567e-02 -8.31161961e-02 -4.68424633e-02\n",
            " -1.60931751e-01  3.37129496e-02  1.56303849e-02 -5.74556254e-02\n",
            "  7.45921433e-02 -7.25743920e-02  6.92641288e-02  1.21151194e-01\n",
            "  5.40232956e-02 -1.74847767e-02 -1.20867558e-01  1.33736998e-01\n",
            "  5.88809736e-02  7.43049160e-02  8.39700103e-02 -1.25494562e-02\n",
            "  1.80744845e-02 -9.82917324e-02  4.23655799e-03 -2.45576743e-02\n",
            " -1.28920615e-01  1.17216222e-01  3.09843179e-02 -7.57374465e-02\n",
            " -2.25040205e-02 -1.24080880e-02 -6.57743588e-02 -6.16131946e-02\n",
            " -2.88157742e-02  3.07509471e-02  8.63970593e-02  5.40627874e-02\n",
            " -8.20456147e-02  3.70375700e-02  1.03354059e-01 -1.23003796e-02\n",
            " -8.58549252e-02  2.04647295e-04  2.45572254e-02 -7.56171718e-02\n",
            " -3.15156840e-02  1.90537404e-02  3.19896042e-02 -7.12172538e-02\n",
            "  6.13367409e-02 -1.82286873e-01 -5.53481169e-02 -6.52717147e-03\n",
            " -1.83033660e-01 -3.98703180e-02  6.28303066e-02 -1.92889050e-02\n",
            " -6.14983067e-02 -4.60959040e-02 -6.93505257e-02  1.68421119e-02\n",
            " -2.48736218e-02  7.56405070e-02 -1.01833567e-01 -8.25051665e-02\n",
            " -5.76423183e-02 -8.22717994e-02 -1.00061752e-01 -3.48044001e-02\n",
            "  1.39590651e-01 -1.25962198e-01 -4.59199771e-03 -1.11031927e-01\n",
            "  3.20452526e-02  1.01332724e-01 -1.04001217e-01  8.43721282e-05\n",
            " -1.06922820e-01 -1.96748618e-02  4.17193258e-03 -8.04102272e-02\n",
            "  5.49269281e-02 -7.34558105e-02 -4.94169332e-02  1.50067940e-01\n",
            " -5.75082451e-02  5.00371605e-02 -1.57330677e-01 -1.79515173e-05\n",
            "  1.16975673e-01 -8.90395232e-03 -5.05371094e-02  4.29579802e-02\n",
            "  2.38037109e-03  2.71929577e-02  6.02165684e-02 -4.06996794e-02\n",
            " -1.01327337e-02 -7.28867501e-02  8.56846049e-02  2.08955649e-02\n",
            "  8.90395232e-03 -3.00651994e-02  5.86511940e-02  1.01946667e-02\n",
            "  1.23665303e-01 -3.81146595e-02 -2.92753335e-02 -1.32378973e-02\n",
            " -6.23707473e-02  2.64964392e-03  1.40553191e-01  1.05124079e-02\n",
            "  2.73581110e-02 -7.92128593e-02 -4.89932783e-02 -9.20257568e-02\n",
            "  9.52148438e-03 -2.88660382e-03 -1.00858800e-01  1.75249889e-01\n",
            " -3.77699919e-03 -2.69919001e-02 -5.41327968e-02 -7.29011074e-02\n",
            " -4.82608564e-02 -1.21029122e-02  5.39981620e-03 -7.86994491e-03\n",
            " -1.17187500e-02  3.15767191e-02  4.12346330e-03 -1.99629832e-02\n",
            "  1.59754142e-01 -9.17681493e-03 -1.09705307e-01 -1.95204783e-02\n",
            "  8.84237885e-02  7.97011405e-02  2.38530785e-02 -1.15880631e-01\n",
            " -3.24994251e-02 -5.28672151e-03 -6.06438145e-02  1.09105729e-01\n",
            " -6.45536557e-02 -6.92659244e-02 -1.30758844e-02 -6.59610555e-02\n",
            " -8.70828032e-02 -1.13561293e-02 -4.34211269e-02  3.21511663e-02\n",
            " -1.05461568e-01  1.56512097e-01  4.89645563e-02  2.75196750e-02\n",
            " -1.28173828e-02 -5.76638617e-02 -4.71029840e-02  4.16587386e-03\n",
            "  1.04233682e-01 -2.07878556e-03 -7.93959647e-02  1.21610753e-01\n",
            " -1.42477602e-01  9.32724923e-02 -9.67766270e-02  8.99658203e-02\n",
            " -2.41757557e-02 -1.18497964e-02 -1.00889765e-01 -1.95985679e-02]\n",
            "Dimensions/Size of Baseline Vector: 300\n",
            "Fine-tuned Vector: [ 7.4547413e-04  2.7130716e-03 -1.5766233e-04  7.0696347e-04\n",
            "  2.8517740e-04 -2.0267395e-03  1.7091417e-03  3.4188582e-03\n",
            "  2.4898082e-04  3.0498573e-05  6.1468460e-04 -2.2582111e-03\n",
            "  5.3871493e-04  4.2584719e-04 -1.5300959e-03 -1.1045440e-03\n",
            "  8.7881956e-04 -2.2693604e-04  2.2244208e-04 -3.8754471e-04\n",
            " -1.8948625e-03 -3.5127287e-04  8.6196017e-04  8.0412108e-04\n",
            "  8.0448028e-04  5.7583535e-04 -2.9123665e-03  1.9427427e-04\n",
            " -8.4103242e-04 -1.5545617e-03  9.5890154e-04 -1.9632366e-03\n",
            "  1.7316183e-03 -7.3057157e-04 -7.6054339e-04  1.9704220e-03\n",
            "  1.0825222e-03 -1.1765647e-03 -2.1492105e-04 -5.0479546e-04\n",
            " -2.1914416e-03  2.0629429e-04  3.1586064e-04 -5.3452572e-04\n",
            "  2.0195988e-03  1.4112816e-03 -5.2136278e-05  1.6144883e-04\n",
            " -3.6780079e-04  2.6104751e-03  3.1522173e-04  1.0660581e-03\n",
            " -1.7127364e-03  8.7685074e-04 -1.9022601e-04  1.2006296e-03\n",
            "  1.9089137e-03 -8.5429667e-05  1.0140906e-03 -1.4934811e-04\n",
            " -1.4903500e-03 -1.0568225e-03  4.6838727e-04  1.1070515e-03\n",
            " -9.8418829e-04  1.1954803e-03 -3.2187675e-04  1.2968349e-03\n",
            " -1.2049676e-03 -3.0492863e-04  3.1204015e-04  4.0752851e-04\n",
            "  2.2303760e-03 -1.1727028e-03  1.6178435e-04 -7.1473012e-05\n",
            " -2.2130436e-03  2.5248516e-04 -1.0002102e-03  5.3610827e-04\n",
            " -1.5603038e-03 -2.3498682e-03  1.2852826e-04  2.8878273e-03\n",
            "  1.1722747e-03  3.1351665e-04 -1.0433932e-03  3.6042638e-04\n",
            "  2.4966716e-03  9.4224821e-04  2.0727201e-03 -1.3891467e-03\n",
            "  1.0189249e-03  8.9766472e-05  1.9603230e-03  1.6938350e-03\n",
            "  1.4185031e-03  8.4249041e-05 -1.6855143e-03  1.3020035e-03\n",
            "  2.9670421e-04  2.1441336e-04  9.5304764e-05 -1.8433864e-04\n",
            " -8.3827000e-04 -2.6833793e-04  1.3640100e-03 -5.0350576e-05\n",
            " -1.9309401e-03  1.5059137e-03 -2.9403337e-03 -7.6501537e-04\n",
            "  7.9742470e-04  1.1493491e-03  1.6112496e-03 -1.7840852e-04\n",
            " -5.1253010e-04  1.8987256e-04  2.0758931e-03 -2.4783826e-03\n",
            "  2.1656202e-03  1.9402922e-03  1.1245077e-03  8.3554485e-05\n",
            " -6.6545460e-04  4.5206124e-04 -2.1555337e-05 -2.0679492e-03\n",
            " -2.8041133e-05  1.2125334e-03  1.8980263e-03  1.7581537e-03\n",
            "  7.7088649e-04 -2.2851462e-03  1.3153894e-03  7.8276068e-04\n",
            " -4.8921013e-04 -1.0815739e-03 -2.7296254e-03 -2.1577245e-03\n",
            " -2.6879233e-04 -1.9639905e-03 -8.4879011e-04  1.7763393e-03\n",
            "  1.4046641e-03 -1.4961917e-03 -1.9090697e-03 -1.7083159e-03\n",
            "  5.7356333e-04 -7.3225587e-04 -4.4779552e-04 -2.9607327e-03\n",
            " -1.6702531e-03 -9.7808184e-04 -4.6434891e-04  1.2535467e-03\n",
            " -2.3054373e-03 -1.0250548e-03 -3.2662961e-04  2.1842381e-03\n",
            "  1.2051227e-03  9.6906163e-04 -1.9816400e-03  2.4955003e-03\n",
            " -1.6248644e-03  1.0207477e-03 -1.0245537e-03 -2.5615949e-04\n",
            " -2.1857157e-04  3.9542373e-03 -1.4174451e-03  2.9017794e-04\n",
            "  1.1048377e-03  3.5510189e-04  5.0752587e-05 -4.2502135e-05\n",
            " -3.3717728e-04 -1.6611331e-03 -2.2756717e-04  4.1256289e-04\n",
            " -1.8040487e-04  1.0296139e-03 -2.1612926e-03 -9.7137236e-04\n",
            " -3.3871597e-04 -3.7483731e-04  3.1681780e-03  1.8141600e-03\n",
            "  4.0712766e-04 -1.7131292e-03  1.0076297e-03  1.1010733e-03\n",
            " -2.1311515e-03 -9.4967667e-04  9.1962435e-04 -2.4420631e-03\n",
            "  9.6192368e-04 -2.1872078e-03  4.3644928e-04 -8.8571840e-05\n",
            " -2.3783797e-03 -4.5252297e-04 -9.8601263e-04 -3.3205163e-04\n",
            " -2.7830724e-04 -1.1628701e-03 -2.6565284e-04  5.0707557e-04\n",
            " -5.3969421e-04 -4.6727169e-04 -1.0801577e-03 -2.0970968e-03\n",
            " -1.5314593e-03  5.3950553e-05  4.5033882e-04 -2.7227895e-03\n",
            " -5.5589213e-04 -3.8670052e-03 -2.7629156e-03 -1.6766542e-03\n",
            "  7.2524545e-04  6.3466089e-04 -1.6821335e-03 -6.2348600e-04\n",
            " -4.1100741e-04 -8.1504841e-04  1.1109146e-03 -5.1320490e-04\n",
            " -9.4224937e-04  1.0865548e-03  1.0888763e-03 -6.2942963e-05\n",
            " -1.5396335e-03  1.7911214e-03 -4.7871465e-04  5.5039098e-04\n",
            "  1.2723259e-03  1.4701867e-03  8.6623710e-04 -3.0364438e-03\n",
            "  7.6922029e-04 -9.5101952e-04 -5.2508322e-04 -7.4605714e-04\n",
            " -4.4206259e-05 -1.7358579e-03 -6.1334250e-04  5.8181747e-04\n",
            " -7.3547853e-04  1.3907166e-03  2.6831619e-04 -3.6760498e-06\n",
            "  1.6038110e-03  3.0708343e-05 -3.5949063e-03 -9.3023345e-04\n",
            "  3.5206575e-03  6.6416094e-04 -3.1251865e-03 -1.1376254e-03\n",
            "  1.5940889e-03  2.0712437e-03  8.2505052e-04 -2.7153755e-03\n",
            " -1.9649034e-03 -3.9176887e-04  3.5767487e-04  4.2465972e-04\n",
            " -2.5820178e-03  7.0745253e-04 -6.4227392e-04  5.5783510e-04\n",
            "  1.4837663e-05 -5.6839501e-04  1.4309293e-03  4.4349441e-04\n",
            "  1.9581160e-03  1.2000004e-03 -1.7969281e-03  3.9255864e-04\n",
            "  2.3042960e-03 -3.5840634e-04 -3.4637656e-04  1.0614210e-03\n",
            "  5.7684630e-04 -1.8323229e-04 -2.4010306e-03  1.1093570e-03\n",
            " -9.0446218e-04  2.1115814e-03 -6.4000080e-04  2.7619917e-03\n",
            "  1.3456306e-03  9.1339584e-04  1.5465301e-03  2.7024215e-03\n",
            "  5.1690190e-04 -1.6610253e-03 -4.4675191e-05  1.0234587e-03]\n",
            "Dimensions/Size of Fine-tuned Vector: 300\n",
            "Cosine Similarity between baseline and fine-tuned vectors: 0.012747211\n"
          ]
        }
      ]
    }
  ]
}